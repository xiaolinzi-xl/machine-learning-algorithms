## 梯度下降法

- 不是一个机器学习算法
- 是一种基于搜索的最优化方法
- 作用：最小化一个损失函数
- 梯度上升法：最大化一个效用函数

---

导数可以代表方向，对应J增大的方向

- n称为学习率
- n的取值影响获得最优解的速度
- n取值不合适，甚至得不到最优解
- n是梯度下降法的一个超参数

n太小，减慢收敛学习速度；n太大，可能导致不收敛。

局部最优解

全局最优解

并不是所有函数都有唯一的极值点

解决方案：

- 多次运行，随机化初始点
- 梯度下降法的初始点也是一个超参数

---

线性回归法的损失函数具有唯一的最优解

随机梯度下降法：

n = a / (i_iters + b) 模拟退火的思想

---

关于梯度的调试

---

批量梯度下降法

随机梯度下降法

小批量随机梯度下降法

---

随机

- 跳出局部最优解
- 更快的运行速度
- 机器学习领域很多算法都要使用随机的特点：随机搜索，随机森林

---

梯度可以代表方向，对应J增大的方向



